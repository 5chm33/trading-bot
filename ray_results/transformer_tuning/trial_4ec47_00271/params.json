{
  "batch_size": 64,
  "dropout_rate": 0.15657592037056833,
  "ff_dim": 256,
  "l2_reg": 0.006102899948106999,
  "learning_rate": 0.0002307757880305162,
  "num_heads": 8,
  "num_layers": 2
}